# Load necessary libraries
library(randomForest)
library(tidyverse)
library(lubridate)
library(doParallel)
library(iml)        # For SHAP, PDP, ICE
library(forecast)   # For autocorrelation diagnostics
library(PerformanceAnalytics)  # For Sharpe ratio
library(zoo)        # For forward filling NA values
library(openxlsx)   # For Excel writing

# Step 1: Extract AAPL data from signals_list
cat("Step 1: Extracting AAPL data...\n")
tryCatch({
    aapl_data <- signals_list[["AAPL US Equity"]]
}, error = function(e) {
    stop("Error in Step 1: Failed to extract AAPL data.\n", e$message)
})

# Step 2: Ensure Date is in Date format and data is sorted
cat("Step 2: Formatting and sorting data...\n")
tryCatch({
    aapl_data <- aapl_data %>% 
        mutate(Date = as.Date(Date)) %>% 
        arrange(Date)
}, error = function(e) {
    stop("Error in Step 2: Formatting and sorting failed.\n", e$message)
})

# Step 3: Add external predictors dynamically (only VIX)
cat("Step 3: Adding VIX data...\n")
tryCatch({
    if (!exists("vix_data")) {
        stop("vix_data is not loaded. Please load the VIX data into the environment before running the script.")
    }
    
    # Rename 'VIX.Adjusted' to 'VIX' if it exists
    if ("VIX.Adjusted" %in% colnames(vix_data)) {
        colnames(vix_data)[colnames(vix_data) == "VIX.Adjusted"] <- "VIX"
    }
    
    # Convert 'Date' to Date type if necessary
    vix_data$Date <- as.Date(vix_data$Date)
    
    # Remove rows with missing VIX values
    vix_data <- vix_data %>% filter(!is.na(VIX))
    
    # Merge VIX data with AAPL data
    cat("Merging VIX data with aapl_data...\n")
    aapl_data <- aapl_data %>% left_join(vix_data, by = "Date")
}, error = function(e) {
    stop("Error in Step 3: Adding external predictors failed.\n", e$message)
})

# Step 4: Add required features dynamically
cat("Step 4: Adding features dynamically...\n")
tryCatch({
    # Forward fill missing values in Bollinger Bands
    aapl_data <- aapl_data %>% 
        mutate(
            BB_Upper = na.locf(BB_Upper, na.rm = FALSE),
            BB_Lower = na.locf(BB_Lower, na.rm = FALSE)
        )
    
    # Replace remaining NA values with 0
    aapl_data <- aapl_data %>% 
        mutate(
            BB_Upper = ifelse(is.na(BB_Upper), 0, BB_Upper),
            BB_Lower = ifelse(is.na(BB_Lower), 0, BB_Lower)
        )
    
    # Add dynamic features
    aapl_data <- aapl_data %>% 
        mutate(
            Band_Width = BB_Upper - BB_Lower,
            Proximity_to_Upper = BB_Upper - Price,
            Proximity_to_Lower = Price - BB_Lower,
            Band_Width_Lag1 = lag(Band_Width, 1),
            Z_Statistic_Lag1 = lag(Z_Statistic, 1),
            Interaction_BW_VIX = Band_Width * VIX,
            return_1d = (lead(Price, 1) - Price) / Price,
            return_5d = (lead(Price, 5) - Price) / Price,
            return_10d = (lead(Price, 10) - Price) / Price
        ) %>% 
        drop_na(Band_Width, Proximity_to_Upper, Proximity_to_Lower, 
                Band_Width_Lag1, Z_Statistic_Lag1, return_1d, return_5d, return_10d)
}, error = function(e) {
    stop("Error in Step 4: Feature engineering failed.\n", e$message)
})

# Step 5: Split the dataset using time-series validation
cat("Step 5: Splitting dataset into training and testing sets...\n")
tryCatch({
    cut_off_date <- "2020-01-01"  # Define split date
    train_data <- aapl_data %>% filter(Date < as.Date(cut_off_date))
    test_data <- aapl_data %>% filter(Date >= as.Date(cut_off_date))
}, error = function(e) {
    stop("Error in Step 5: Data splitting failed.\n", e$message)
})

# Step 6: Set Date column as rownames
cat("Step 6: Setting Date as rownames for train and test data...\n")
train_data <- train_data %>% column_to_rownames(var = "Date")
test_data <- test_data %>% column_to_rownames(var = "Date")

# Step 7: Set up parallelisation
cat("Step 7: Setting up parallelisation...\n")
tryCatch({
    cl <- makeCluster(detectCores() - 1)
    registerDoParallel(cl)
}, error = function(e) {
    stop("Error in Step 7: Parallelisation setup failed.\n", e$message)
})

# Step 8: Define evaluation metrics
evaluate_metrics <- function(predictions, actuals, threshold = 0) {
    directional_accuracy <- mean(sign(predictions) == sign(actuals))
    hit_rate <- mean(predictions > threshold & actuals > threshold)
    sharpe_ratio <- SharpeRatio(predictions - actuals, Rf = 0.02 / 252, p = 0.95)
    
    return(data.frame(
        Directional_Accuracy = directional_accuracy,
        Hit_Rate = hit_rate,
        Sharpe_Ratio = sharpe_ratio
    ))
}

# Step 9: Hyperparameter Tuning with Grid Search using tuneRF for 1-day, 5-day, and 10-day models
cat("Step 9: Hyperparameter tuning with tuneRF for 1-day, 5-day, and 10-day...\n")

# Hyperparameter tuning for 1-day model
tune_1d <- tuneRF(
  x = train_data[, c("Band_Width", "Proximity_to_Upper", "Proximity_to_Lower", "VIX", 
                     "Band_Width_Lag1", "Z_Statistic_Lag1", "Interaction_BW_VIX")],
  y = train_data$return_1d,                    
  mtryStart = 3,                                
  ntreeTry = 500,                               
  stepFactor = 1.5,                             
  improve = 0.01,                              
  trace = TRUE,                                 
  plot = FALSE                                   
)

# Hyperparameter tuning for 5-day model
tune_5d <- tuneRF(
  x = train_data[, c("Band_Width", "Proximity_to_Upper", "Proximity_to_Lower", "VIX", 
                     "Band_Width_Lag1", "Z_Statistic_Lag1", "Interaction_BW_VIX")],
  y = train_data$return_5d,                    
  mtryStart = 3,                                
  ntreeTry = 500,                               
  stepFactor = 1.5,                             
  improve = 0.01,                              
  trace = TRUE,                                 
  plot = FALSE                                   
)

# Hyperparameter tuning for 10-day model
tune_10d <- tuneRF(
  x = train_data[, c("Band_Width", "Proximity_to_Upper", "Proximity_to_Lower", "VIX", 
                     "Band_Width_Lag1", "Z_Statistic_Lag1", "Interaction_BW_VIX")],
  y = train_data$return_10d,                    
  mtryStart = 3,                                
  ntreeTry = 500,                               
  stepFactor = 1.5,                             
  improve = 0.01,                              
  trace = TRUE,                                 
  plot = FALSE                                   
)

# Step 10: Train final models for each prediction horizon
final_rf_model_1d <- randomForest(
    return_1d ~ Band_Width + Proximity_to_Upper + Proximity_to_Lower + VIX +
        Band_Width_Lag1 + Z_Statistic_Lag1 + Interaction_BW_VIX,
    data = train_data,
    ntree = 500,
    mtry = tune_1d[1, "mtry"],
    importance = TRUE
)

final_rf_model_5d <- randomForest(
    return_5d ~ Band_Width + Proximity_to_Upper + Proximity_to_Lower + VIX +
        Band_Width_Lag1 + Z_Statistic_Lag1 + Interaction_BW_VIX,
    data = train_data,
    ntree = 500,
    mtry = tune_5d[1, "mtry"],
    importance = TRUE
)

final_rf_model_10d <- randomForest(
    return_10d ~ Band_Width + Proximity_to_Upper + Proximity_to_Lower + VIX +
        Band_Width_Lag1 + Z_Statistic_Lag1 + Interaction_BW_VIX,
    data = train_data,
    ntree = 500,
    mtry = tune_10d[1, "mtry"],
    importance = TRUE
)

# Step 11: Evaluate models and save performance metrics
metrics_1d <- evaluate_metrics(predict(final_rf_model_1d, test_data), test_data$return_1d)
metrics_5d <- evaluate_metrics(predict(final_rf_model_5d, test_data), test_data$return_5d)
metrics_10d <- evaluate_metrics(predict(final_rf_model_10d, test_data), test_data$return_10d)

# Combine metrics into a dataframe
model_metrics <- bind_rows(
  data.frame(Model = "1-day", metrics_1d),
  data.frame(Model = "5-day", metrics_5d),
  data.frame(Model = "10-day", metrics_10d)
)

# Save metrics as CSV
write.csv(model_metrics, "model_performance_metrics.csv", row.names = FALSE)

# Step 12: Save Actual vs Predicted Plots
png("predictions_vs_actuals_1d.png", width = 3000, height = 3000)
plot(predict(final_rf_model_1d, test_data), test_data$return_1d, 
     main = "1-Day Predictions vs Actuals", 
     xlab = "Predicted Returns", ylab = "Actual Returns", col = "blue", pch = 16)
abline(0, 1, col = "red")
dev.off()

png("predictions_vs_actuals_5d.png", width = 3000, height = 3000)
plot(predict(final_rf_model_5d, test_data), test_data$return_5d, 
     main = "5-Day Predictions vs Actuals", 
     xlab = "Predicted Returns", ylab = "Actual Returns", col = "blue", pch = 16)
abline(0, 1, col = "red")
dev.off()

png("predictions_vs_actuals_10d.png", width = 3000, height = 3000)
plot(predict(final_rf_model_10d, test_data), test_data$return_10d, 
     main = "10-Day Predictions vs Actuals", 
     xlab = "Predicted Returns", ylab = "Actual Returns", col = "blue", pch = 16)
abline(0, 1, col = "red")
dev.off()

# Step 13: Save performance metrics in Excel
write.xlsx(list("1-day" = metrics_1d, "5-day" = metrics_5d, "10-day" = metrics_10d, "Summary" = model_metrics), 
           "model_performance_metrics.xlsx")

# Stop the parallel cluster
stopCluster(cl)

