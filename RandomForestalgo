# Load necessary libraries
library(randomForest)
library(tidyverse)
library(lubridate)
library(doParallel)
library(iml)        # For SHAP, PDP, ICE
library(forecast)   # For autocorrelation diagnostics
library(PerformanceAnalytics)  # For Sharpe ratio
library(zoo)        # For forward filling NA values

# Step 1: Extract AAPL data from signals_list
cat("Step 1: Extracting AAPL data...\n")
tryCatch({
  aapl_data <- signals_list[["AAPL US Equity"]]
}, error = function(e) {
  stop("Error in Step 1: Failed to extract AAPL data.\n", e$message)
})

# Step 2: Ensure Date is in Date format and data is sorted
cat("Step 2: Formatting and sorting data...\n")
tryCatch({
  aapl_data <- aapl_data %>% 
    mutate(Date = as.Date(Date)) %>% 
    arrange(Date)
}, error = function(e) {
  stop("Error in Step 2: Formatting and sorting failed.\n", e$message)
})

# Step 3: Add external predictors dynamically (only VIX)
cat("Step 3: Adding VIX data...\n")
tryCatch({
  # Check if vix_data is already loaded
  if (!exists("vix_data")) {
    stop("vix_data is not loaded. Please load the VIX data into the environment before running the script.")
  }
  
  # Rename 'VIX.Adjusted' to 'VIX' if it exists
  if ("VIX.Adjusted" %in% colnames(vix_data)) {
    colnames(vix_data)[colnames(vix_data) == "VIX.Adjusted"] <- "VIX"
  }
  
  # Convert 'Date' to Date type if necessary
  vix_data$Date <- as.Date(vix_data$Date)
  
  # Remove rows with missing VIX values
  vix_data <- vix_data %>% filter(!is.na(VIX))
  
  # Merge VIX data with AAPL data
  cat("Merging VIX data with aapl_data...\n")
  aapl_data <- aapl_data %>% 
    left_join(vix_data, by = "Date")
}, error = function(e) {
  stop("Error in Step 3: Adding external predictors failed.\n", e$message)
})

# Step 4: Add required features dynamically
cat("Step 4: Adding features dynamically...\n")
tryCatch({
  # Forward fill missing values in Bollinger Bands
  aapl_data <- aapl_data %>%
    mutate(
      BB_Upper = na.locf(BB_Upper, na.rm = FALSE),
      BB_Lower = na.locf(BB_Lower, na.rm = FALSE)
    )
  
  # Replace remaining NA values with 0
  aapl_data <- aapl_data %>%
    mutate(
      BB_Upper = ifelse(is.na(BB_Upper), 0, BB_Upper),
      BB_Lower = ifelse(is.na(BB_Lower), 0, BB_Lower)
    )
  
  # Add dynamic features
  aapl_data <- aapl_data %>%
    mutate(
      Band_Width = BB_Upper - BB_Lower,
      Proximity_to_Upper = BB_Upper - Price,
      Proximity_to_Lower = Price - BB_Lower,
      Band_Width_Lag1 = lag(Band_Width, 1),
      Z_Statistic_Lag1 = lag(Z_Statistic, 1),
      Interaction_BW_VIX = Band_Width * VIX,
      return_1d = (lead(Price, 1) - Price) / Price,
      return_5d = (lead(Price, 5) - Price) / Price,
      return_10d = (lead(Price, 10) - Price) / Price
    ) %>%
    drop_na(Band_Width, Proximity_to_Upper, Proximity_to_Lower, 
            Band_Width_Lag1, Z_Statistic_Lag1, return_1d, return_5d, return_10d)
}, error = function(e) {
  stop("Error in Step 4: Feature engineering failed.\n", e$message)
})

# Step 5: Split the dataset using time-series validation
cat("Step 5: Splitting dataset into training and testing sets...\n")
tryCatch({
  cut_off_date <- "2020-01-01"  # Define split date
  train_data <- aapl_data %>% filter(Date < as.Date(cut_off_date))
  test_data <- aapl_data %>% filter(Date >= as.Date(cut_off_date))
}, error = function(e) {
  stop("Error in Step 5: Data splitting failed.\n", e$message)
})

# Step 6: Set Date column as rownames
cat("Step 6: Setting Date as rownames for train and test data...\n")
train_data <- train_data %>% column_to_rownames(var = "Date")
test_data <- test_data %>% column_to_rownames(var = "Date")

# Step 7: Set up parallelisation
cat("Step 7: Setting up parallelisation...\n")
tryCatch({
  cl <- makeCluster(detectCores() - 1)
  registerDoParallel(cl)
}, error = function(e) {
  stop("Error in Step 7: Parallelisation setup failed.\n", e$message)
})

# Step 8: Define evaluation metrics
evaluate_metrics <- function(predictions, actuals, threshold = 0) {
  directional_accuracy <- mean(sign(predictions) == sign(actuals))
  hit_rate <- mean(predictions > threshold & actuals > threshold)
  sharpe_ratio <- SharpeRatio(predictions - actuals, Rf = 0.02 / 252, p = 0.95)
  list(Directional_Accuracy = directional_accuracy, Hit_Rate = hit_rate, Sharpe_Ratio = sharpe_ratio)
}

# Step 9: Hyperparameter Tuning with Grid Search using tuneRF
cat("Step 9: Hyperparameter tuning with tuneRF...\n")

# Perform hyperparameter tuning with tuneRF
tune_results <- tuneRF(
  x = train_data[, c("Band_Width", "Proximity_to_Upper", "Proximity_to_Lower", "VIX", 
                     "Band_Width_Lag1", "Z_Statistic_Lag1", "Interaction_BW_VIX")],
  y = train_data$return_1d,                     # Target variable
  mtryStart = 3,                                # Initial mtry value
  ntreeTry = 500,                               # Number of trees
  stepFactor = 1.5,                             # How much to increase mtry at each step
  improve = 0.01,                               # Minimum improvement required
  trace = TRUE,                                 # Print progress
  plot = FALSE                                   # Plot performance (disable)
)

cat("Best mtry from tuning:\n")
print(tune_results)

# Step 10: Train the final model with optimal parameters
cat("Step 10: Training final Random Forest model...\n")
final_rf_model <- randomForest(
  return_1d ~ Band_Width + Proximity_to_Upper + Proximity_to_Lower + VIX +
    Band_Width_Lag1 + Z_Statistic_Lag1 + Interaction_BW_VIX,
  data = train_data,
  ntree = 500,                                # Fixed number of trees
  mtry = tune_results[1, "mtry"],             # Optimal mtry from tuning
  importance = TRUE                           # Importance of features
)

# Step 11: Evaluate the final model on the test data
cat("Step 11: Evaluating final model on test data...\n")
predictions <- predict(final_rf_model, test_data)
metrics <- evaluate_metrics(predictions, test_data$return_1d)
cat("Evaluation metrics for final model:\n")
print(metrics)

# Save the final tuned model
cat("Step 12: Saving the final model...\n")
saveRDS(final_rf_model, "final_rf_tuned_model.rds")

# Step 13: Save plot to PNG with 10000x10000 resolution
cat("Step 13: Saving the plot...\n")
png("evaluation_metrics_plot.png", width = 10000, height = 10000)  # Save plot as PNG

# Plot the evaluation metrics
par(mfrow = c(1, 3), mar = c(5, 5, 2, 1))  # Adjusted margins
plot(metrics$Directional_Accuracy, main = "Directional Accuracy", col = "blue", pch = 16)
plot(metrics$Hit_Rate, main = "Hit Rate", col = "green", pch = 16)
plot(metrics$Sharpe_Ratio, main = "Sharpe Ratio", col = "red", pch = 16)

# Close the PNG device
dev.off()

# Stop the parallel cluster
stopCluster(cl)
